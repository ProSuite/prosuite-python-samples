{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to Using the ProSuite Python Script\n",
    "This script demonstrates how to use the ProSuite Python API to create a simple quality specification (without a DDX!)\n",
    "and run a here specified verification on a dataset.\n",
    "It also demonstrates how to handle issues that are returned from the verification\n",
    "and how to control the verification process based on the issues.\n",
    "### Table of Contents:\n",
    "1. [Prerequisites](#prerequisites)\n",
    "2. [Connecting to the ProSuite QA Service](#connecting-to-the-prosuite-qa-service)\n",
    "3. [Running Different QA Checks](#running-different-qa-checks)\n",
    "    1. [Minimum Length Check](#minimum-length-check)\n",
    "    2. [Segment Length Check](#segment-length-check)\n",
    "    3. [Using a Shapefile for Perimeter](#using-a-shapefile-for-perimeter)\n",
    "    4. [Applying an SQL Query for Filter](#applying-an-sql-query-for-filter)\n",
    "4. [Loading Perimeter from a Shapefile](#loading-perimeter-from-a-shapefile)\n",
    "5. [Using SQL Queries as Dataset Filters](#using-sql-queries-as-dataset-filters)\n",
    "6. [Verifying a Specification](#verifying-a-specification)\n",
    "7. [Handling Verification Issues](#handling-verification-issues)\n",
    "8. [Generating Output and Logs](#generating-output-and-logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    " 1. **Install the ProSuite Python API (installation instructions can be found in the official ProSuite documentation).**\n",
    " 2. **Make sure to run Pip from the Python distribution/environment where you need ProSuite to be installed. pip install prosuite**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosuite as ps\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import subprocess\n",
    "import socket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. **Set the Path to Your Dataset**\n",
    "\n",
    "    To use geospatial data (e.g., `.gdb` or `.sde`), follow these steps:\n",
    "\n",
    "    Using the Sample Dataset from ProSuite:\n",
    "    1. **Download the Sample Dataset**:\n",
    "    - Visit the [ProSuite API Samples](https://www.dirageosystems.ch/prosuite/doc/api/samples.html) page.\n",
    "     - Download and extract the dataset (e.g., to `C:/ProSuiteSampleData/`).\n",
    "\n",
    "    2. **Adjust the Path in Your Script**:\n",
    "    - After extracting, update your script to point to the correct `.gdb` file location. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\jpfra\\AppData\\Local\\Temp\\ipykernel_32204\\1849169924.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  model_path = \"C:\\DIRA\\SampelData\\TLM_I.gdb\"  # Replace this with the path to your model\n",
      "C:\\Users\\jpfra\\AppData\\Local\\Temp\\ipykernel_32204\\1849169924.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  output_dir = \"C:\\DIRA\\Output\"  # Replace this with the path to your output directory\n"
     ]
    }
   ],
   "source": [
    "model_path = \"C:\\DIRA\\SampelData\\TLM_I.gdb\"  # Replace this with the path to your model\n",
    "output_dir = \"C:\\DIRA\\Output\"  # Replace this with the path to your output directory\n",
    "\n",
    "model = ps.Model(\"TopoModel\", model_path)\n",
    "datasets = [ps.Dataset(\"TLM_FLIESSGEWAESSER_I\", model),\n",
    "            ps.Dataset(\"TLM_STRASSE_I\", model)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4. **Start the ProSuite QA Microservice**\n",
    "\n",
    "    You have two options to start the ProSuite microservice:\n",
    "\n",
    "    1. **Start Manually**:\n",
    "    - Navigate to the folder where the `prosuite-qa-microservice.exe` is located.\n",
    "    - Double-click the `.exe` file to start the service.\n",
    "\n",
    "    2. **Start via Script**:\n",
    "     - Alternatively, you can start the service programmatically using Python. Update the file path in the script to the location where your `prosuite-qa-microservice.exe` is stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProSuite service is already running at localhost:5151.\n",
      "Skipping service start as it's already running.\n"
     ]
    }
   ],
   "source": [
    "# Check if the service is running\n",
    "if not is_service_running():\n",
    "    print(\"Starting the ProSuite service...\")\n",
    "    try:\n",
    "        # Start the ProSuite service if not already running\n",
    "        server_process = subprocess.Popen(r\"C:\\git\\Dira.ProSuiteSolution\\binServer_x64\\Debug\")\n",
    "        \n",
    "        # Wait for the service to start\n",
    "        time.sleep(10)\n",
    "        print(\"ProSuite service started.\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"PermissionError: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting ProSuite service: {e}\")\n",
    "else:\n",
    "    print(\"Skipping service start as it's already running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the ProSuite QA Service\n",
    "\n",
    "To run quality assurance checks, you first need to establish a connection to the ProSuite QA microservice. You can either doThis is done using the `Service` class, which allows communication between your Python script and the ProSuite server. FOr usual the  default the communication channel is http://localhost:5151."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the ProSuite service on localhost:5151\n",
      "Ready to run QA checks.\n"
     ]
    }
   ],
   "source": [
    "service = create_service('localhost', 5151)  # Adjust host and port if needed\n",
    "\n",
    "if service:\n",
    "    # Proceed with your QA checks if the service is created successfully\n",
    "    print(\"Ready to run QA checks.\")\n",
    "else:\n",
    "    print(\"Cannot proceed without connecting to the ProSuite service.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a QA Check with a Defined Geographic Perimeter or a choosen Shapefile as perimeter\n",
    "\n",
    "In this section, the user runs a Quality Assurance (QA) check by specifying the type of check (e.g., `min_length`, `segment_length`....) and defining a geographic perimeter ore defining the path to a shp file to use as an `EnvelopePerimeter`.\n",
    "\n",
    "#### Key Steps:\n",
    "\n",
    "1. **Deciding Between Shapefile Input or Manually Defined Perimeter**:\n",
    "   - The user has the option to either:\n",
    "     - Use a **Shapefile** to define the geographic perimeter.\n",
    "     - Manually define the perimeter using coordinates (`x_min`, `y_min`, `x_max`, `y_max`).\n",
    "   - **`use_shapefile`**: A boolean flag that determines whether to load a perimeter from a Shapefile (`True`) or define it directly (`False`).\n",
    "\n",
    "2. **Choosing the Check Type**:\n",
    "   - The `check_type` variable allows the user to specify which QA check to run.\n",
    "     - **`min_length`**: Verifies that features meet a specified minimum length.\n",
    "     - **`segment_length`**: Verifies the length of individual segments within features.\n",
    "     - **`xxx`**: to be defined\n",
    "     - **`xxx`**: to be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Envelope loaded from shapefile: C:\\DIRA\\Output\\Output.shp\n",
      "Connected to ProSuite service on localhost:5151\n",
      "Creating external issue file geodatabase\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "Starting quality verification using quality specification MinimumLengthSpecification with verification tile size 5000Extent: 15172 x 8911\n",
      "  X-Min: 2750673\n",
      "  Y-Min: 1206640\n",
      "  X-Max: 2765845\n",
      "  Y-Max: 1215551\n",
      "\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "Verifying quality conditions per cached tiles (container tests)\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 0 of 8: XMin: 2 750 673,00 YMin: 1 206 640,00 XMax: 2 755 673,00 YMax: 1 211 640,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 1 of 8: XMin: 2 755 673,00 YMin: 1 206 640,00 XMax: 2 760 673,00 YMax: 1 211 640,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 2 of 8: XMin: 2 760 673,00 YMin: 1 206 640,00 XMax: 2 765 673,00 YMax: 1 211 640,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 3 of 8: XMin: 2 765 673,00 YMin: 1 206 640,00 XMax: 2 765 845,00 YMax: 1 211 640,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 4 of 8: XMin: 2 750 673,00 YMin: 1 211 640,00 XMax: 2 755 673,00 YMax: 1 215 551,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 5 of 8: XMin: 2 755 673,00 YMin: 1 211 640,00 XMax: 2 760 673,00 YMax: 1 215 551,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 6 of 8: XMin: 2 760 673,00 YMin: 1 211 640,00 XMax: 2 765 673,00 YMax: 1 215 551,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "  Processing tile 7 of 8: XMin: 2 765 673,00 YMin: 1 211 640,00 XMax: 2 765 845,00 YMax: 1 215 551,00\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "Quality verification finishedNumber of verified datasets: 2.\n",
      "Number of verified conditions: 2\n",
      "No category\n",
      "  QaMinLength(0) TLM_FLIESSGEWAESSER_I\n",
      "  QaMinLength(0) TLM_STRASSE_I\n",
      "Warning count: 0\n",
      "Error count: 0\n",
      "The quality specification is fulfilled\n",
      "\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "Issues written to C:\\DIRA\\Output\\output_20241004_171848\\Issues.gdb\n",
      "\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "Verification report written to C:\\DIRA\\Output\\output_20241004_171848\\verification.xml\n",
      "Html report:\n",
      "C:\\DIRA\\Output\\output_20241004_171848\\verification.html\n",
      "Quality specification report:\n",
      "C:\\DIRA\\Output\\output_20241004_171848\\qualityspecification.html\n",
      "\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "\n",
      "Status: Finished\n",
      "Verification finished successfully\n"
     ]
    }
   ],
   "source": [
    "check_type = 'min_length'  # Options: 'min_length', 'segment_length', etc.\n",
    "\n",
    "# User input\n",
    "use_shapefile = True  # Set to False if the user wants to define the envelope directly\n",
    "use_xml_file = False # Set to True if the user wants to verify using an XML file, otherwise set to False for QA check\n",
    "shapefile_path = 'C:\\\\DIRA\\\\Output\\\\Output.shp'  # The user provides the shapefile path\n",
    "envelope_coordinates = {\n",
    "    'x_min': 2750673,\n",
    "    'y_min': 1215551,\n",
    "    'x_max': 2765845,\n",
    "    'y_max': 1206640\n",
    "}  # Define geographic perimeter\n",
    "\n",
    "xml_file_path = 'C:\\\\DIRA\\\\specifications\\\\road_specification.qa.xml'  # Path to the XML file\n",
    "workspace  = 'C:\\\\DIRA\\\\connection_files\\\\production_QA_version.gdb'  # Path to the .gdb workspace\n",
    "\n",
    "# Determine which process to run based on the boolean flag\n",
    "if use_xml_file:\n",
    "    # Proceed to read and verify using the XML file\n",
    "    try:\n",
    "        xml_spec = prosuite.XmlSpecification(\n",
    "            specification_file=xml_file_path,\n",
    "            specification_name=\"Produktionsunterstuetzung\",\n",
    "            data_source_replacements=[[\"ProductionModel\", workspace]]\n",
    "        )\n",
    "        \n",
    "        verification_responses = service.verify(specification=xml_spec, output_dir=output_dir)\n",
    "        for verification_response in verification_responses:\n",
    "            print(verification_response.message)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read XML specification or run verification: {e}\")\n",
    "\n",
    "else:\n",
    "    # Proceed to run the QA check\n",
    "    # Determine which envelope to use\n",
    "    if use_shapefile:\n",
    "        envelope = load_envelope_from_shapefile(shapefile_path)\n",
    "    else:\n",
    "        envelope = ps.EnvelopePerimeter(**envelope_coordinates)\n",
    "\n",
    "# Call the selected check\n",
    "select_and_run_qa_check(check_type, model, datasets, output_dir, envelope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "## Definitions (No User Changes Required)\n",
    "\n",
    "From this point onward, the code contains function definitions that are fully implemented and **do not require any modifications by the user**. These functions handle the specific details of running the Quality Assurance (QA) checks, connecting to the ProSuite service, and managing the verification process.\n",
    "\n",
    "#### Important Information:\n",
    "\n",
    "- The most critical sections of the code where the user needs to interact or set parameters (such as the **check type**, **model**, **datasets**, **output directory**, and **geographic envelope**) have already been explained earlier.\n",
    "- The functions below handle various QA checks and internal logic, ensuring that the verification process runs smoothly without further configuration.\n",
    "\n",
    "Feel free to explore these functions to understand their purpose, but no changes are necessary unless you're adding new types of checks.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: `select_and_run_qa_check`\n",
    "\n",
    "This function lets you run various QA checks based on the `check_type` provided.\n",
    "\n",
    "**Key Parameters:**\n",
    "- **`check_type`**: The type of QA check (e.g., `min_length`, `segment_length`).\n",
    "- **`model`**: The data model.\n",
    "- **`datasets`**: The datasets to check.\n",
    "- **`output_dir`**: The directory for the output.\n",
    "- **`envelope`**: The geographic area for the check.\n",
    "\n",
    "**Supported QA Checks:**\n",
    "1. **Minimum Length Check**: Ensures features meet a minimum length.\n",
    "2. **Segment Length Check**: Ensures segments within features meet a minimum length.\n",
    "\n",
    "**Example Usage:**\n",
    "- `min_length`: Verifies features are at least 10 units long.\n",
    "- `segment_length`: Verifies segments are at least 1.5 units long.\n",
    "\n",
    "**Additional Checks:**  \n",
    "You can add more checks by extending the `select_and_run_qa_check` function.\n",
    "\n",
    "\n",
    "\n",
    "#### QA Check Functions:\n",
    "\n",
    "1. **`qa_min_length_check(model, datasets, output_dir, envelope)`**:  \n",
    "   Verifies that features meet a minimum length requirement (e.g., 10 units).\n",
    "\n",
    "2. **`qa_segment_length_check(model, datasets, output_dir, envelope)`**:  \n",
    "   Verifies that segments within features are at least 1.5 units long.\n",
    "\n",
    "Both functions create a **specification** in ProSuite, add the necessary conditions, and run the verification process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_and_run_qa_check(check_type, model, datasets, output_dir, envelope):\n",
    "    if check_type == 'min_length':\n",
    "        qa_min_length_check(model, datasets, output_dir, envelope)\n",
    "    elif check_type == 'segment_length':\n",
    "        qa_segment_length_check(model, datasets, output_dir, envelope)\n",
    "    # Add more conditions for other checks\n",
    "    #elif check_type == 'another_check':\n",
    "    #    another_check(model, datasets, output_dir, envelope)\n",
    "    # Add more conditions for other checks\n",
    "    else:\n",
    "        print(f\"Unknown check type: {check_type}\")\n",
    "\n",
    "#------------------------ QA CHECKS ------------------------    \n",
    "def qa_min_length_check(model, datasets, output_dir, envelope):\n",
    "    specification = ps.Specification(\n",
    "        name='MinimumLengthSpecification',\n",
    "        description='A QA check for minimum feature length of roads and rivers.')\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        specification.add_condition(ps.Conditions.qa_min_length_0(dataset, limit=10, is3_d=False))\n",
    "    \n",
    "    run_verification(specification, output_dir, envelope)\n",
    "\n",
    "# Function to create and run a \"Segment Length\" QA check\n",
    "def qa_segment_length_check(model, datasets, output_dir, envelope):\n",
    "    specification = ps.Specification(\n",
    "        name='SegmentLengthSpecification',\n",
    "        description='A QA check for segment length of roads and rivers.')\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        specification.add_condition(ps.Conditions.qa_segment_length_0(dataset, 1.5, False))\n",
    "    \n",
    "    run_verification(specification, output_dir, envelope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: `run_verification(specification, output_dir, envelope)`\n",
    "\n",
    "This function handles the process of connecting to the ProSuite service, running the verification with a specified quality assurance (QA) specification, and managing the verification output.\n",
    "\n",
    "##### Key Steps:\n",
    "\n",
    "1. **Generating a Timestamped Output Directory**:\n",
    "   - The function first creates an output directory with a unique timestamp to store the verification results. This ensures that every run generates a distinct set of outputs.\n",
    "   ```python\n",
    "   output_dir_with_timestamp = os.path.join(output_dir, f'output_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "   os.makedirs(output_dir_with_timestamp, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_verification(specification, output_dir, envelope):\n",
    "    # Generate a timestamped directory for output\n",
    "    output_dir_with_timestamp = os.path.join(output_dir, f'output_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "    os.makedirs(output_dir_with_timestamp, exist_ok=True)\n",
    "    \n",
    "    # Connect to the service\n",
    "    try:\n",
    "        service = ps.Service(host_name='localhost', port_nr=5151)\n",
    "        print(f\"Connected to ProSuite service on localhost:5151\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to ProSuite service: {e}\")\n",
    "        return\n",
    "\n",
    "    # Run the verification\n",
    "    try:\n",
    "        verification_responses = service.verify(specification=specification, output_dir=output_dir_with_timestamp, perimeter=envelope)\n",
    "        \n",
    "        issue_allowable = True  # This will control whether the process continues if non-allowable issues are found\n",
    "        \n",
    "        for verification_response in verification_responses:\n",
    "            # Print general verification message\n",
    "            print(verification_response.message)\n",
    "            \n",
    "            # Check for issues\n",
    "            if len(verification_response.issues) > 0:\n",
    "                for issue in verification_response.issues:\n",
    "                    # Print issue details\n",
    "                    print(issue.description)\n",
    "                    print(issue.involved_objects)\n",
    "                    print(issue.geometry)\n",
    "                    print(issue.issue_code)\n",
    "                    print(issue.allowable)\n",
    "                    print(issue.stop_condition)\n",
    "\n",
    "                    # If an issue is not allowable, stop the verification\n",
    "                    if not issue.allowable:\n",
    "                        print(f\"Not allowed issue met: {issue.description} in {issue.involved_objects[0].table_name}\")\n",
    "                        print(\"Stopping verification\")\n",
    "                        issue_allowable = False\n",
    "                        break\n",
    "\n",
    "            # Break the outer loop if any non-allowable issue is found\n",
    "            if not issue_allowable:\n",
    "                break\n",
    "            \n",
    "            # Print the service call status\n",
    "            print(\"Status: \" + verification_response.service_call_status)\n",
    "\n",
    "            # Handle different statuses\n",
    "            if verification_response.service_call_status == \"Failed\":\n",
    "                print(\"Server not accessible, check licence\")\n",
    "                print(\"Verification Response:\" + verification_response.message)\n",
    "            elif verification_response.service_call_status == \"Running\":\n",
    "                print(\"Server accessible, code running\")\n",
    "            elif verification_response.service_call_status == \"Cancelled\":\n",
    "                print(\"Verification cancelled\")\n",
    "            elif verification_response.service_call_status == \"Finished\":\n",
    "                print(\"Verification finished successfully\")\n",
    "            else:\n",
    "                print(\"Undefined status\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Verification failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_service_running(host='localhost', port=5151):\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        try:\n",
    "            s.connect((host, port))\n",
    "            print(f\"ProSuite service is already running at {host}:{port}.\")\n",
    "            return True\n",
    "        except ConnectionRefusedError:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_service(host_name, port_nr):\n",
    "    \"\"\"\n",
    "    Creates a connection to the ProSuite QA service and provides feedback on success or failure.\n",
    "    \n",
    "    :param host_name: The hostname of the ProSuite QA service.\n",
    "    :param port_nr: The port number used by the service.\n",
    "    :return: A ProSuite service object or None if the connection fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to create the service instance\n",
    "        service = ps.Service(host_name=host_name, port_nr=port_nr)\n",
    "        print(f\"Successfully connected to the ProSuite service on {host_name}:{port_nr}\")\n",
    "        return service\n",
    "    except Exception as e:\n",
    "        # Catch any exceptions and provide feedback\n",
    "        print(f\"Failed to connect to the ProSuite service on {host_name}:{port_nr}. Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_envelope_from_shapefile(shapefile_path):\n",
    "    try:\n",
    "        gdf = gpd.read_file(shapefile_path)\n",
    "        bounds = gdf.total_bounds  # Returns (minx, miny, maxx, maxy)\n",
    "        envelope = ps.EnvelopePerimeter(x_min=bounds[0], y_min=bounds[1], x_max=bounds[2], y_max=bounds[3])\n",
    "        print(f\"Envelope loaded from shapefile: {shapefile_path}\")\n",
    "        return envelope\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading shapefile: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FileGdb workspace 'C:/temp/verification_output_20\\Issues.gdb' already exists\n",
      "Status: Running\n",
      "Server accessible, code running\n",
      "\n",
      "Status: Failed\n",
      "Server not accessible, check licence\n",
      "Verification Response:\n"
     ]
    }
   ],
   "source": [
    "#------------------------OLD CODE------------------------\n",
    "\n",
    "\n",
    "simpleSpecification = ps.Specification(\n",
    "    name='MinimumLengthSpecification',\n",
    "    description='A very simple quality specification checking feature and segment length of roads and rivers')\n",
    "\n",
    "for dataset in datasets:\n",
    "    simpleSpecification.add_condition(ps.Conditions.qa_min_length_0(dataset, limit=10, is3_d=False))\n",
    "    simpleSpecification.add_condition(ps.Conditions.qa_segment_length_0(dataset, 1.5, False))\n",
    "\n",
    "envelope = ps.EnvelopePerimeter(x_min=2750673, y_min=1215551, x_max=2765845, y_max=1206640)\n",
    "\n",
    "out_dir = 'C:/temp/verification_output_20' # You might want to change this to a directory that exists on your system, also make sure no Issue.gdb exists in this directory\n",
    "\n",
    "verification_responses = service.verify(specification=simpleSpecification, output_dir=out_dir, perimeter=envelope)\n",
    "\n",
    "# 3. Run Verification and handle issues with the Issue Object\n",
    "\n",
    "issue_allowable = True\n",
    "\n",
    "for verification_response in verification_responses:\n",
    "    print(verification_response.message)\n",
    "    if len(verification_response.issues) > 0:\n",
    "        for issue in verification_response.issues:\n",
    "            # Demo Prints\n",
    "\n",
    "            print(issue.description)\n",
    "            print(issue.involved_objects)\n",
    "            print(issue.geometry)\n",
    "            print(issue.issue_code)\n",
    "            print(issue.allowable)\n",
    "            print(issue.stop_condition)\n",
    "\n",
    "            if issue.allowable is False:\n",
    "                print(f\"Not allowed issue met: {issue.description} in {issue.involved_objects[0].table_name}\")\n",
    "                print(\"Stopping verification\")\n",
    "                issue_allowable = False\n",
    "                break\n",
    "\n",
    "    if issue_allowable is False:\n",
    "        break\n",
    "\n",
    "    print(\"Status: \"+verification_response.service_call_status)\n",
    "\n",
    "    if(verification_response.service_call_status == \"Failed\" ):\n",
    "        print(\"Server not accessible, check licence\")\n",
    "        print(\"Verification Response:\"+verification_response.message)\n",
    "    elif(verification_response.service_call_status == \"Running\"):\n",
    "        print(\"Server accessible, code running\")\n",
    "    elif(verification_response.service_call_status == \"Cancelled\"):\n",
    "        print(\"Cancelled\")\n",
    "    elif(verification_response.service_call_status == \"Finished\"):\n",
    "        print(\"Server accessible, code finished running\")\n",
    "    else:\n",
    "         print(\"Undifined\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egm_2024_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
